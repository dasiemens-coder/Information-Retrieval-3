{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from adarankv2 import AdaRank2\n",
    "from adarank import AdaRank\n",
    "from metrics import NDCGScorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#define file path\n",
    "file_path = 'loinc_ranks_query_moreterms.xlsx'\n",
    "# Load pretrained model vector embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely calculate similarity between a query and a field\n",
    "def calculate_embedding_similarity(query, field):\n",
    "    if pd.isna(query) or pd.isna(field):\n",
    "        return 0\n",
    "    query_embedding = embedder.encode([str(query)])[0]\n",
    "    field_embedding = embedder.encode([str(field)])[0]\n",
    "    return cosine_similarity([query_embedding], [field_embedding])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the\n",
    "xls = pd.ExcelFile(file_path)\n",
    "dataframes = []\n",
    "for sheet_name in xls.sheet_names:\n",
    "    temp_df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    temp_df['query'] = sheet_name  # Each sheet name is used as the query text\n",
    "    dataframes.append(temp_df)\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Compute cosine similarity using TF-IDF\n",
    "# We want to compute, for each row, the cosine similarity between the query and the long_common_name.\n",
    "# First, build a TF-IDF vectorizer fitted on the union of all queries and names.\n",
    "corpus = pd.concat([merged_df['query'], merged_df['long_common_name']])\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the query and long_common_name columns\n",
    "X_query = vectorizer.transform(merged_df['query'])\n",
    "X_name_tfidf = vectorizer.transform(merged_df['long_common_name'])\n",
    "\n",
    "# Compute cosine similarity for each row\n",
    "cosine_sim = np.array([cosine_similarity(X_query[i], X_name_tfidf[i])[0, 0] \n",
    "                         for i in range(X_query.shape[0])])\n",
    "merged_df['name_cosine_sim'] = cosine_sim\n",
    "\n",
    "# Now use the computed cosine similarity as the feature for the name field.\n",
    "X_name = csr_matrix(merged_df[['name_cosine_sim']].values)\n",
    "\n",
    "# ------------------------------\n",
    "# Process additional features\n",
    "# Drop loin_ID as queries are natural text \n",
    "# X_loinc_ID = TfidfVectorizer().fit_transform(merged_df['loinc_num'])\n",
    "\n",
    "# Create similarity scores for features measurement, system, and component\n",
    "# Apply a similarity function to each row, based on vector embeddings \n",
    "merged_df['measurement_similarity'] = merged_df.apply(\n",
    "    lambda row: calculate_embedding_similarity(row['query'], row['long_common_name']), axis=1)\n",
    "merged_df['system_similarity'] = merged_df.apply(\n",
    "    lambda row: calculate_embedding_similarity(row['query'], row['system']), axis=1)\n",
    "merged_df['component_similarity'] = merged_df.apply(\n",
    "    lambda row: calculate_embedding_similarity(row['query'], row['component']), axis=1)\n",
    "\n",
    "# Convert to sparse matrices\n",
    "X_measurement_similarity = csr_matrix(merged_df[['measurement_similarity']].values)\n",
    "X_system_similarity = csr_matrix(merged_df[['system_similarity']].values)\n",
    "X_component_similarity = csr_matrix(merged_df[['component_similarity']].values)\n",
    "\n",
    "# ------------------------------\n",
    "# Process numerical feature: 'rank' (scaled)\n",
    "scaler = StandardScaler()\n",
    "X_rank = scaler.fit_transform(merged_df[['rank']])\n",
    "X_rank_sparse = csr_matrix(X_rank)\n",
    "\n",
    "# ------------------------------\n",
    "# Combine all features into one sparse matrix.\n",
    "# Here, we use the computed cosine similarity (X_name) not the full TF-IDF matrix.\n",
    "X = hstack([X_name, X_measurement_similarity, X_system_similarity, \n",
    "            X_component_similarity, X_rank_sparse])\n",
    "\n",
    "# Labels and query identifiers\n",
    "y = merged_df['inSearch'].values\n",
    "# Use a label encoder to convert query strings to integers\n",
    "merged_df['qid_numeric'] = pd.factorize(merged_df['query'])[0]\n",
    "qid = merged_df['qid_numeric'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique queries in train: [1 2 3]\n",
      "Unique queries in test: [0]\n",
      "Unique queries and their frequencies: (array([0, 1, 2, 3]), array([ 97,  97,  97, 100]))\n",
      "X_train:\n",
      " [[ 0.          0.29758579  0.04382028  0.30065224 -0.37530678]\n",
      " [ 0.15084318  0.32261932 -0.00544647  0.18759102 -0.46530982]\n",
      " [ 0.03663183  0.20796832  0.13492452  0.08134238 -0.41042425]\n",
      " ...\n",
      " [ 0.01716352  0.18149579  0.01239809 -0.00329014 -0.47089141]\n",
      " [ 0.0167173   0.17618269  0.01239809 -0.0077756  -0.47089141]\n",
      " [ 0.01817638  0.18151717  0.01239809  0.02372467  0.27983161]]\n",
      "y_train: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X_train summary stats (mean, std): [ 0.0823937   0.28062859  0.024979    0.16415865 -0.00691751] [0.12277105 0.18595759 0.05094936 0.20695168 1.01036578]\n",
      "y_train distribution: (array([0, 1]), array([258,  36]))\n",
      "y_train summary stats (mean, std): 0.12244897959183673 0.3278036409022247\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EPSILON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Train and evaluate AdaRank\u001b[39;00m\n\u001b[32m     29\u001b[39m model = AdaRank(max_iter=\u001b[32m100\u001b[39m, estop=\u001b[32m10\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m, scorer=NDCGScorer(k=\u001b[32m5\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqid_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m20\u001b[39m):\n\u001b[32m     33\u001b[39m     score = NDCGScorer(k=k)(y_test, y_pred, qid_test).mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/Information-Retrieval-3/adarank.py:86\u001b[39m, in \u001b[36mAdaRank.fit\u001b[39m\u001b[34m(self, X, y, qid, X_valid, y_valid, qid_valid)\u001b[39m\n\u001b[32m     82\u001b[39m EPS = \u001b[32m1e-8\u001b[39m\n\u001b[32m     83\u001b[39m h = best_weak_ranker\n\u001b[32m     84\u001b[39m h[\u001b[33m'\u001b[39m\u001b[33malpha\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m0.5\u001b[39m * math.log(\n\u001b[32m     85\u001b[39m     np.dot(weights, \u001b[32m1\u001b[39m + h[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m]) /\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28mmax\u001b[39m(np.dot(weights, \u001b[32m1\u001b[39m - h[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m]), \u001b[43mEPSILON\u001b[49m)\n\u001b[32m     87\u001b[39m )\n\u001b[32m     88\u001b[39m weak_rankers.append(h)\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# update the ranker\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'EPSILON' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Query-aware train/test splitting\n",
    "splitter = GroupShuffleSplit(test_size=0.2, random_state=None)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups=qid))\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "qid_train, qid_test = qid[train_idx], qid[test_idx]\n",
    "\n",
    "# Create DataFrames for the train and test sets using the respective indices\n",
    "train_df = merged_df.iloc[train_idx].copy()\n",
    "test_df = merged_df.iloc[test_idx].copy()\n",
    "\n",
    "print(\"Unique queries in train:\", np.unique(qid[train_idx]))\n",
    "print(\"Unique queries in test:\", np.unique(qid[test_idx]))\n",
    "\n",
    "print(\"Unique queries and their frequencies:\", np.unique(qid, return_counts=True))\n",
    "\n",
    "\n",
    "print(\"X_train:\\n\", X_train.toarray())\n",
    "print(\"y_train:\", y_train)\n",
    "#Check basic statistics to identify issues\n",
    "print(\"X_train summary stats (mean, std):\", np.mean(X_train.toarray(), axis=0), np.std(X_train.toarray(), axis=0))\n",
    "print(\"y_train distribution:\", np.unique(y_train, return_counts=True))\n",
    "print(\"y_train summary stats (mean, std):\", np.mean(y_train, axis=0), np.std(y_train, axis=0))\n",
    "\n",
    "# ------------------------------\n",
    "# Train and evaluate AdaRank\n",
    "model = AdaRank(max_iter=100, estop=10, verbose=True, scorer=NDCGScorer(k=5))\n",
    "model.fit(X_train, y_train, qid_train)\n",
    "\n",
    "for k in (1, 2, 3, 4, 5, 10, 20):\n",
    "    score = NDCGScorer(k=k)(y_test, y_pred, qid_test).mean()\n",
    "    y_pred = model.predict(X_test, qid_test)    \n",
    "    print(f\"NDCG Score {score}, K {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique queries in test: 1\n",
      "['bilirubin in plasma']\n",
      "Number of distinct queries overall: 4\n",
      "['glucose in blood' 'bilirubin in plasma' 'White blood cells count'\n",
      " 'cholesterol in blood']\n",
      "Top Predictions per Query:\n",
      "Query: bilirubin in plasma\n",
      "    loinc_num                                   long_common_name  y_true  \\\n",
      "98     1742-6  Alanine aminotransferase [Enzymatic activity/v...       0   \n",
      "99    20565-8      Carbon dioxide, total [Moles/volume] in Blood       0   \n",
      "171   35672-5  Bilirubin.direct/Bilirubin.total in Serum or P...       1   \n",
      "170   14630-8  Bilirubin.indirect [Moles/volume] in Serum or ...       1   \n",
      "169   35192-4  Bilirubin.indirect [Mass or Moles/volume] in S...       1   \n",
      "168    1971-1  Bilirubin.indirect [Mass/volume] in Serum or P...       1   \n",
      "167   15153-0  Deprecated Indirect bilirubin [Mass/volume] in...       1   \n",
      "166   50189-0  Neonatal bilirubin panel [Mass/volume] - Serum...       1   \n",
      "165   33899-6  Bilirubin.conjugated+indirect [Moles/volume] i...       1   \n",
      "164   33898-8  Bilirubin.conjugated+indirect [Mass/volume] in...       1   \n",
      "163    1988-5  C reactive protein [Mass/volume] in Serum or P...       0   \n",
      "162   33870-7  Bilirubin.total [Presence] in Unspecified spec...       0   \n",
      "161    1995-0  Calcium.ionized [Moles/volume] in Serum or Plasma       0   \n",
      "160    2085-9  Cholesterol in HDL [Mass/volume] in Serum or P...       0   \n",
      "159    1920-8  Aspartate aminotransferase [Enzymatic activity...       0   \n",
      "158   54439-5                Calcium bilirubinate/Total in Stone       0   \n",
      "156    4671-4                  Protein C [Mass/volume] in Plasma       0   \n",
      "155    2075-0         Chloride [Moles/volume] in Serum or Plasma       0   \n",
      "154    1798-8  Amylase [Enzymatic activity/volume] in Serum o...       0   \n",
      "172   43820-0     Bilirubin.direct [Presence] in Serum or Plasma       1   \n",
      "173   34442-4  Bilirubin.conjugated/Bilirubin.total in Serum ...       1   \n",
      "174  102052-8  1-Deoxysphingosine [Mass/volume] in Serum by L...       0   \n",
      "185   15267-8  Tree Allergen Mix 6 (Boxelder+Silver birch+Ame...       0   \n",
      "192   23797-4  Tree Allergen Mix 2 (Boxelder+White oak+White ...       0   \n",
      "191   82031-6  Tree Allergen Mix 2 (Boxelder+White oak+White ...       0   \n",
      "190   24479-8  Tree Allergen Mix 1 (Boxelder+Silver birch+Whi...       0   \n",
      "189   15262-9  Tree Allergen Mix 1 (Boxelder+Silver birch+Whi...       0   \n",
      "188   30184-6  Tree Allergen Mix 1 (Boxelder+Silver birch+Whi...       0   \n",
      "187   23796-6  Deprecated Tree Allergen Mix 1 (Boxelder+Silve...       0   \n",
      "186   82034-0  Tree Allergen Mix 6 (Boxelder+Silver birch+Ame...       0   \n",
      "184   82035-7  Tree Allergen Mix 6 (Boxelder+Silver birch+Ame...       0   \n",
      "175   93418-2  (8;8)(q13;q21)(HEY1,NCOA2) fusion transcript [...       0   \n",
      "183   24134-9  Deprecated Tree Allergen Mix 6 (Boxelder+Silve...       0   \n",
      "182   82037-3  Tree Allergen Mix 8 (Boxelder+Silver birch+Haz...       0   \n",
      "181   15270-2  Tree Allergen Mix 8 (Boxelder+Silver birch+Haz...       0   \n",
      "180   50653-5  Tree Allergen Mix 8 (Boxelder+Silver birch+Haz...       0   \n",
      "178   82087-8  Occupational Allergen Mix 2 (Acarus siro+Lepid...       0   \n",
      "177   15236-3  Occupational Allergen Mix 2 (Acarus siro+Lepid...       0   \n",
      "176   82088-6  Occupational Allergen Mix 2 (Acarus siro+Lepid...       0   \n",
      "152    6768-6  Alkaline phosphatase [Enzymatic activity/volum...       0   \n",
      "151    2069-3                   Chloride [Moles/volume] in Blood       0   \n",
      "150   35184-1  Fasting glucose [Mass or Moles/volume] in Seru...       0   \n",
      "112    2093-3       Cholesterol [Mass/volume] in Serum or Plasma       0   \n",
      "123     883-9                          ABO group [Type] in Blood       0   \n",
      "122    2028-9  Carbon dioxide, total [Moles/volume] in Serum ...       0   \n",
      "121    1759-0   Albumin/Globulin [Mass ratio] in Serum or Plasma       0   \n",
      "120   17861-6           Calcium [Mass/volume] in Serum or Plasma       0   \n",
      "119   14578-9  ABO group [Type] in Blood from Blood product unit       0   \n",
      "118     890-4  Blood group antibody screen [Presence] in Seru...       0   \n",
      "113   10331-7                                 Rh [Type] in Blood       0   \n",
      "\n",
      "     y_pred  \n",
      "98      inf  \n",
      "99      inf  \n",
      "171     inf  \n",
      "170     inf  \n",
      "169     inf  \n",
      "168     inf  \n",
      "167     inf  \n",
      "166     inf  \n",
      "165     inf  \n",
      "164     inf  \n",
      "163     inf  \n",
      "162     inf  \n",
      "161     inf  \n",
      "160     inf  \n",
      "159     inf  \n",
      "158     inf  \n",
      "156     inf  \n",
      "155     inf  \n",
      "154     inf  \n",
      "172     inf  \n",
      "173     inf  \n",
      "174     inf  \n",
      "185     inf  \n",
      "192     inf  \n",
      "191     inf  \n",
      "190     inf  \n",
      "189     inf  \n",
      "188     inf  \n",
      "187     inf  \n",
      "186     inf  \n",
      "184     inf  \n",
      "175     inf  \n",
      "183     inf  \n",
      "182     inf  \n",
      "181     inf  \n",
      "180     inf  \n",
      "178     inf  \n",
      "177     inf  \n",
      "176     inf  \n",
      "152     inf  \n",
      "151     inf  \n",
      "150     inf  \n",
      "112     inf  \n",
      "123     inf  \n",
      "122     inf  \n",
      "121     inf  \n",
      "120     inf  \n",
      "119     inf  \n",
      "118     inf  \n",
      "113     inf  \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the test set using the test indices\n",
    "test_df = merged_df.iloc[test_idx].copy()\n",
    "test_df['y_true'] = y_test\n",
    "test_df['y_pred'] = y_pred\n",
    "\n",
    "#debugging tests \n",
    "unique_test_queries = np.unique(qid_test)\n",
    "print(\"Number of unique queries in test:\", len(unique_test_queries))\n",
    "print(unique_test_queries)\n",
    "\n",
    "all_queries = merged_df['query'].unique()\n",
    "print(\"Number of distinct queries overall:\", len(all_queries))\n",
    "print(all_queries)\n",
    "\n",
    "# for each query in the test set, print the top 3 predictions (sorted by predicted score)\n",
    "print(\"Top Predictions per Query:\")\n",
    "for query, group in test_df.groupby('query'):\n",
    "    sorted_group = group.sort_values(by='y_pred', ascending=False)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(sorted_group[['loinc_num', 'long_common_name', 'y_true', 'y_pred']].head(50))\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
