{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval, Extraction and Integration\n",
    "## Assignment 3: ML Ranking Assignment\n",
    "### EIT Digital Innovation - Data Science \n",
    "- Davis Siemens\n",
    "- Inés Simón del Collado\n",
    "- Xiya Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1350,
     "status": "ok",
     "timestamp": 1741193186722,
     "user": {
      "displayName": "Inés Simón del Collado",
      "userId": "16799051721855248348"
     },
     "user_tz": -60
    },
    "id": "jKSalNKQKnlm",
    "outputId": "9801eff3-e16c-4049-fad8-4958951d276a"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1741195782984,
     "user": {
      "displayName": "Inés Simón del Collado",
      "userId": "16799051721855248348"
     },
     "user_tz": -60
    },
    "id": "C1K7hpuWM5ee"
   },
   "outputs": [],
   "source": [
    "# Load Excel file\n",
    "excel_file = \"loinc_dataset-v2.xlsx\"\n",
    "\n",
    "# API Base URL (example, update as needed)\n",
    "api_url = \"https://loinc.regenstrief.org/searchapi/loincs\"\n",
    "\n",
    "# Authentication credentials\n",
    "auth = (\"davissiemens\", \"jejben-3rykVi-fejzaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1741195784747,
     "user": {
      "displayName": "Inés Simón del Collado",
      "userId": "16799051721855248348"
     },
     "user_tz": -60
    },
    "id": "Nxs5UfM2MMiY"
   },
   "outputs": [],
   "source": [
    "# Function to get ranking for a LOINC code\n",
    "def get_loinc_data(loinc_num):\n",
    "    params = {\"query\": loinc_num, \"rows\": 1}  # Search parameter\n",
    "    response = requests.get(api_url, params=params, auth=auth)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"Results\" in data and len(data[\"Results\"]) > 0:\n",
    "            # Extract the COMMON_TEST_RANK\n",
    "            return data[\"Results\"][0].get(\"COMMON_TEST_RANK\", \"No Rank Found\")\n",
    "    return \"Not Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1741196534163,
     "user": {
      "displayName": "Inés Simón del Collado",
      "userId": "16799051721855248348"
     },
     "user_tz": -60
    },
    "id": "etgBWH_SWID2"
   },
   "outputs": [],
   "source": [
    "# Function to check if a LOINC code is related to \"glucose in blood\"\n",
    "def check_query(loinc_code, query_search):\n",
    "    # Searching for \"glucose in blood\" in the LOINC database\n",
    "    params = {\"query\": query_search, \"rows\": 800}  # Adjust query for glucose search\n",
    "    response = requests.get(api_url, params=params, auth=auth)  # API call with authentication\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Check if any of the results have the same LOINC code\n",
    "        for result in data.get(\"Results\", []):\n",
    "            if result.get(\"LOINC_NUM\") == loinc_code:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111198,
     "status": "ok",
     "timestamp": 1741196646662,
     "user": {
      "displayName": "Inés Simón del Collado",
      "userId": "16799051721855248348"
     },
     "user_tz": -60
    },
    "id": "AoABPV8FQOjL",
    "outputId": "18027ac4-e6fc-4592-8f82-3b612051e78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet: glucose in blood\n",
      "Processing sheet: bilirubin in plasma\n",
      "Processing sheet: White blood cells count\n",
      "LOINC rankings saved to loinc_ranks_query.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Read all sheets from the Excel file\n",
    "excel_sheets = pd.read_excel(excel_file, sheet_name=None, skiprows=2)\n",
    "\n",
    "# Prepare a dictionary to hold the results\n",
    "result_dict = {}\n",
    "\n",
    "# Loop through each sheet in the Excel file\n",
    "for sheet_name, df in excel_sheets.items():\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "    # Assuming LOINC codes are in a column named 'LOINC Code'\n",
    "    df[\"rank\"] = df[\"loinc_num\"].astype(str).apply(get_loinc_data)\n",
    "\n",
    "    df[\"inSearch\"] = df[\"loinc_num\"].astype(str).apply(lambda x: check_query(x, sheet_name))\n",
    "\n",
    "    # Save the results for each sheet in the result_dict\n",
    "    result_dict[sheet_name] = df\n",
    "\n",
    "# Save the results to a new Excel file with multiple sheets\n",
    "with pd.ExcelWriter(\"./loinc_ranks_query.xlsx\") as writer:\n",
    "    for sheet_name, df in result_dict.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"LOINC rankings saved to loinc_ranks_query.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all related, and then we take xnumber\n",
    "def get_allrelated_loincs(query, num_results=10):\n",
    "    \"\"\"\n",
    "    Fetches relevant/unrelevant documents from the LOINC API based on search query (sheets names)\n",
    "    \"\"\"\n",
    "    params = {\"query\": query, \"rows\": num_results*100}\n",
    "    response = requests.get(api_url, params=params, auth=auth)\n",
    "\n",
    "    results = []\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for result in data.get(\"Results\", []):\n",
    "            results.append({\n",
    "                \"loinc_num\": result.get(\"LOINC_NUM\", \"Unknown\"),\n",
    "                \"long_common_name\": result.get(\"LONG_COMMON_NAME\", \"Unknown\"),\n",
    "                \"component\": result.get(\"COMPONENT\", \"Unknown\"),\n",
    "                \"system\": result.get(\"SYSTEM\", \"Unknown\"),\n",
    "                \"property\": result.get(\"PROPERTY\", \"Unknown\"),\n",
    "                \"rank\": result.get(\"COMMON_TEST_RANK\", \"No Rank Found\"),\n",
    "                \"inSearch\": 1  # Mark as related\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create and storage a dataset from LOINC, so we dont have to run the analysis many times\n",
    "# from this dataset, we will build the testing dataset and get the top unrelated.\n",
    "def get_top_loinc_entries(min_rank=10000, num_results=5000):\n",
    "    \"\"\"\n",
    "    Fetches LOINC entries where COMMON_TEST_RANK > min_rank and selects the top 'num_results'.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"query\": \"*\",\n",
    "        \"rows\": num_results * 10,  # Fetch more to ensure we have enough ranked results\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params, auth=auth)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data from LOINC API\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on failure\n",
    "\n",
    "    data = response.json()\n",
    "    results = []\n",
    "\n",
    "    for result in data.get(\"Results\", []):\n",
    "        rank = result.get(\"COMMON_TEST_RANK\", None)\n",
    "        if rank and int(rank) < min_rank:  # Only keep ranks < 5000 (top 5000, to ensure more variety)\n",
    "            results.append({\n",
    "                \"loinc_num\": result.get(\"LOINC_NUM\", \"Unknown\"),\n",
    "                \"long_common_name\": result.get(\"LONG_COMMON_NAME\", \"Unknown\"),\n",
    "                \"component\": result.get(\"COMPONENT\", \"Unknown\"),\n",
    "                \"system\": result.get(\"SYSTEM\", \"Unknown\"),\n",
    "                \"property\": result.get(\"PROPERTY\", \"Unknown\"),\n",
    "                \"rank\": int(rank)  # Convert to integer\n",
    "            })\n",
    "\n",
    "    # take randomly num_results amount of documents that are in top 5000\n",
    "    df_results = pd.DataFrame(results).sample(n=min(num_results, len(results)), random_state=42)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we save this dataset, so we do not have to run it that many times\n",
    "top5k_entries = get_top_loinc_entries()\n",
    "len(top5k_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add terms to sheets\n",
    "def add_terms_to_sheets(file_path, sheet_name = None, related = 0, unrelated = 0, top_loinc_entries = top5k_entries):\n",
    "    \"\"\"\n",
    "    Reads the Excel file and adds x related and y unrelated documents to each sheet.\n",
    "    \"\"\"\n",
    "    # Read all sheets from the Excel file\n",
    "    excel_sheets = pd.read_excel(file_path, sheet_name)\n",
    "\n",
    "    # Dictionary to store updated data\n",
    "    updated_sheets = {}\n",
    "\n",
    "    # Iterate through each sheet in the Excel file\n",
    "    for sheet_name, df in excel_sheets.items():\n",
    "        print(f\"Adding documents to sheet: {sheet_name}\")\n",
    "\n",
    "        # Get x_related relevant documents based on the sheet name (query)\n",
    "        df_related = get_allrelated_loincs(sheet_name) #all related\n",
    "        df_x_related = df_related.sample(n=min(related, len(df_related)), random_state=42)  #randomly xnumber of related of the total\n",
    "\n",
    "        # Get y_unrelated documents ensuring no duplicates\n",
    "        existing_loincs = set(df_related[\"loinc_num\"].astype(str))  # all related loincs\n",
    "        df_unrelated = top_loinc_entries[~top_loinc_entries[\"loinc_num\"].isin(existing_loincs)]\n",
    "        df_y_unrelated = df_unrelated.sample(n=min(unrelated, len(df_unrelated)), random_state=42)  #randomly ynumber of unrelated of the total\n",
    "        df_y_unrelated[\"inSearch\"] = 0 #add the column inSearch \n",
    "\n",
    "        # Combine original data with new documents\n",
    "        df_updated = pd.concat([df, df_x_related, df_y_unrelated], ignore_index=True)\n",
    "\n",
    "        # Save updated sheet data\n",
    "        updated_sheets[sheet_name] = df_updated\n",
    "\n",
    "    # Save the updated Excel file with all new rows\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        for sheet_name, df in updated_sheets.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(\"Related and unrelated documents have been successfully added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents to sheet: glucose in blood\n",
      "Adding documents to sheet: bilirubin in plasma\n",
      "Adding documents to sheet: White blood cells count\n",
      "Related and unrelated documents have been successfully added.\n"
     ]
    }
   ],
   "source": [
    "# add terms to the defect sheets\n",
    "add_terms_to_sheets(\"loinc_ranks_query.xlsx\", None, 50, 400, top5k_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_query_sheet(new_query, file_path=\"loinc_ranks_query_terms.xlsx\", related = 50, unrelated = 500, top_loinc_entries = top5k_entries):\n",
    "    \"\"\"\n",
    "    Adds a completely new query and its related documents as a new sheet in the Excel file.\n",
    "    \"\"\"\n",
    "    # Read all existing sheets\n",
    "    excel_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "    print(f\"Adding new query: {new_query}\")\n",
    "\n",
    "    # Get x_related relevant documents based on the sheet name (query)\n",
    "    df_related = get_allrelated_loincs(new_query) #all related\n",
    "    df_x_related = df_related.sample(n=min(related, len(df_related)), random_state=42)  #randomly xnumber of related of the total\n",
    "\n",
    "    # Get y_unrelated documents ensuring no duplicates\n",
    "    existing_loincs = set(df_related[\"loinc_num\"].astype(str))  # all related loincs\n",
    "    df_unrelated = top_loinc_entries[~top_loinc_entries[\"loinc_num\"].isin(existing_loincs)]\n",
    "    df_y_unrelated = df_unrelated.sample(n=min(unrelated, len(df_unrelated)), random_state=42)  #randomly ynumber of unrelated of the total\n",
    "    df_y_unrelated[\"inSearch\"] = 0 #add the column inSearch \n",
    "\n",
    "    # Combine original data with new documents\n",
    "    df_new_sheet = pd.concat([df_x_related, df_y_unrelated], ignore_index=True)\n",
    "    \n",
    "\n",
    "    # Add the new query as a sheet in the Excel file\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        for sheet_name, df in excel_sheets.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Add the new sheet\n",
    "        df_new_sheet.to_excel(writer, sheet_name=new_query, index=False)\n",
    "\n",
    "    print(f\"New sheet '{new_query}' added successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new query: cholesterol in blood\n",
      "New sheet 'cholesterol in blood' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_new_query_sheet(\"cholesterol in blood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new query: fever virus\n",
      "New sheet 'fever virus' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_new_query_sheet(\"fever virus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new query: calcium oxalate crystals\n",
      "New sheet 'calcium oxalate crystals' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_new_query_sheet(\"calcium oxalate crystals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new query: iron\n",
      "New sheet 'iron' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_new_query_sheet(\"iron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new query: PrThr\n",
      "New sheet 'PrThr' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_new_query_sheet(\"PrThr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_loinc_sheet(file_path, number = 500, dataset = top5k_entries):\n",
    "    \"\"\"\n",
    "    Adds a new sheet with the top 200 LOINC entries where rank > 3000 to the existing Excel file.\n",
    "    \"\"\"\n",
    "    # Read all existing sheets\n",
    "    excel_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "    # Fetch top-ranked LOINC entries with rank > 3000\n",
    "    #df_top_loinc = get_top_loinc_entries(min_rank=3000, num_results=200)\n",
    "    df_top_loinc = dataset.sample(n=min(number, len(dataset)), random_state=42)\n",
    "    #df_top_loinc = df_top_loinc.drop(columns=[\"inSearch\"])\n",
    "\n",
    "    # Save updated Excel file with the new sheet\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        for sheet_name, df in excel_sheets.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Add the new sheet with top-ranked LOINC entries\n",
    "        df_top_loinc.to_excel(writer, sheet_name=\"testing\", index=False)\n",
    "\n",
    "    print(\"New sheet 'testing' added successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sheet 'testing' added successfully.\n"
     ]
    }
   ],
   "source": [
    "add_top_loinc_sheet(\"loinc_ranks_query_terms.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQTzH/69t/YkDNUQpczFTB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
